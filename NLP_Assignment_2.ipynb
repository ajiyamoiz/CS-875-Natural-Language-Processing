{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPfwNm38MO0QThYWhhnRIi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Assignment 2\n",
        "\n",
        "## N-Gram Model"
      ],
      "metadata": {
        "id": "fOJhhE3xgrGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment you will use the N-Gram notebook provided in the class.\n",
        "\n",
        "• Use the notebook and implement Laplace smoothing for the N-Gram model to handle 0 counts of the word.\n",
        "\n",
        "• After implementation of the smoothing, also show the impact by displaying some examples."
      ],
      "metadata": {
        "id": "TRjGkLTCgGR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw1hROMpYLrn",
        "outputId": "442adb1b-03f3-47c2-fc41-b73318370a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the corpus\n",
        "corpus = brown.words()\n",
        "\n",
        "# Case folding and getting vocab\n",
        "lower_case_corpus = [w.lower() for w in corpus]\n",
        "vocab = set(lower_case_corpus)\n",
        "\n",
        "print('Total words in Corpus:', len(lower_case_corpus))\n",
        "print('Vocab of the Corpus:', len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJRbwHWiYRz_",
        "outputId": "24b95253-a6c8-457a-f67a-de2964bb005c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in Corpus: 1161192\n",
            "Vocab of the Corpus: 49815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting bigrams and trigrams using Counter\n",
        "bigram_counts = Counter(zip(lower_case_corpus, lower_case_corpus[1:]))\n",
        "trigram_counts = Counter(zip(lower_case_corpus, lower_case_corpus[1:], lower_case_corpus[2:]))\n",
        "\n",
        "print(\"Example, count for bigram ('the', 'king') is: \" + str(bigram_counts[('the', 'king')]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml5UvOwheYQ2",
        "outputId": "16b6af56-be35-4611-8384-804b366c7230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example, count for bigram ('the', 'king') is: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function takes sentence as input and suggests possible words that comes after the sentence\n",
        "def suggest_next_word(input_, bigram_counts, trigram_counts, vocab):\n",
        "    # Splitting the input into tokens\n",
        "    tokens = input_.lower().split()\n",
        "\n",
        "    # Consider the last bigram of the sentence\n",
        "    last_bigram = (tokens[-2], tokens[-1])\n",
        "\n",
        "    # Laplace smoothing parameter\n",
        "    alpha = 1\n",
        "\n",
        "    # Calculating probability for each word in vocab with Laplace smoothing\n",
        "    vocab_probabilities = {}\n",
        "    for vocab_word in vocab:\n",
        "        test_trigram = (last_bigram[0], last_bigram[1], vocab_word)\n",
        "        test_bigram = (last_bigram[0], last_bigram[1])\n",
        "\n",
        "        test_trigram_count = trigram_counts.get(test_trigram, 0)\n",
        "        test_bigram_count = bigram_counts.get(test_bigram, 0)\n",
        "\n",
        "        # Laplace smoothing\n",
        "        probability = (test_trigram_count + alpha) / (test_bigram_count + alpha * len(vocab))\n",
        "        vocab_probabilities[vocab_word] = probability\n",
        "\n",
        "    # Sorting the vocab probability in descending order to get top probable words\n",
        "    top_suggestions = sorted(vocab_probabilities.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "    return top_suggestions"
      ],
      "metadata": {
        "id": "8jv1imRGYiSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences to demonstrate the impact of Laplace smoothing\n",
        "examples = [\n",
        "    'I am the king',\n",
        "    'I am the king of',\n",
        "    'I am the king of france',\n",
        "    'I am the king of france and',\n",
        "    'This is a completely new sentence without any previous context'\n",
        "]\n",
        "\n",
        "for example in examples:\n",
        "    suggestions = suggest_next_word(example, bigram_counts, trigram_counts, vocab)\n",
        "    print(f\"\\nExample: '{example}'\")\n",
        "    print(\"Suggestions:\")\n",
        "    for word, probability in suggestions:\n",
        "        print(f\"  {word}: {probability:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPsKj31gWVAN",
        "outputId": "0ac447ff-51ca-429a-b0b5-4659efc3ad5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example: 'I am the king'\n",
            "Suggestions:\n",
            "  james: 0.00020\n",
            "  of: 0.00018\n",
            "  arthur: 0.00014\n",
            "\n",
            "Example: 'I am the king of'\n",
            "Suggestions:\n",
            "  france: 0.00010\n",
            "  hearts: 0.00006\n",
            "  england: 0.00004\n",
            "\n",
            "Example: 'I am the king of france'\n",
            "Suggestions:\n",
            "  and: 0.00010\n",
            "  .: 0.00010\n",
            "  ,: 0.00008\n",
            "\n",
            "Example: 'I am the king of france and'\n",
            "Suggestions:\n",
            "  the: 0.00008\n",
            "  germany: 0.00006\n",
            "  louisiana: 0.00004\n",
            "\n",
            "Example: 'This is a completely new sentence without any previous context'\n",
            "Suggestions:\n",
            "  constables: 0.00002\n",
            "  dunn's: 0.00002\n",
            "  shawano: 0.00002\n"
          ]
        }
      ]
    }
  ]
}